# Graph-Theoretic-Modeling-and-Explainable-AI-for-Credit-Card-Fraud-Detection

##Overview
Credit card fraud detection remains a critical challenge for financial institutions, as conventional methods often struggle to keep pace with sophisticated and ever-evolving fraudulent activities. This project presents a novel approach that leverages bipartite graph modeling and explainable artificial intelligence (XAI) techniques to enhance the detection and transparency of credit card fraud.

##Abstract
This project constructs a bipartite graph where transactions and cardholders are represented as nodes, with edges denoting their interactions. By modeling transaction data as a graph, our approach enables the identification of suspicious patterns and relationships that may go unnoticed by traditional, non-graph-based methods. To further improve model transparency and trust, we integrate explainable AI tools, such as Local Interpretable Model-agnostic Explanations (LIME), to provide insights into the modelâ€™s decision-making process.

##Our contributions are twofold:

Efficiency: Improved detection of fraudulent activities through advanced graph-based modeling.
Transparency: Enhanced model interpretability using XAI methods, crucial for practical deployment in the financial sector.

##Features
Graph Construction: Transactions and cardholders represented as a bipartite graph.
Fraud Pattern Detection: Identification of complex, hidden relationships in transactional data.
Explainability: Integration of XAI techniques, including LIME, to interpret model decisions.
Scalability: Designed for practical, real-world financial datasets.
Technologies Used:
Python: Core programming language
Graph Neural Networks (GNN)
LIME: For model explanation
NetworkX: For graph construction and analysis
Scikit-learn: For machine learning utilities
HTML/CSS: For visualization and reporting
